{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of BERT Fine-Tuning Sentence Classification v4_Jackson.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2cfb32ada124465193c107f629e46715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fe6cde81f8104a01995eba21b1c66f98",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c989bd8fb3564c9ab0c656e964806584",
              "IPY_MODEL_0eef865155084f9f9cf271e44765fb9a",
              "IPY_MODEL_905384f44e9e41d78eedb759c84bf06c"
            ]
          }
        },
        "fe6cde81f8104a01995eba21b1c66f98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c989bd8fb3564c9ab0c656e964806584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e86dfba8d051433c96fb45bb40d6b4dd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_87fc0ed59fec49b0bf8592a205bfb815"
          }
        },
        "0eef865155084f9f9cf271e44765fb9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b8bb2dd04317442ebeeec528e85e4446",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 364,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 364,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_94342dcf55844b86aa49b0020dea0229"
          }
        },
        "905384f44e9e41d78eedb759c84bf06c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_22c33156634e4a78930276ff7fabb752",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 364/364 [00:00&lt;00:00, 9.63kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_77f5685ad83f453fbc5256b97b559d25"
          }
        },
        "e86dfba8d051433c96fb45bb40d6b4dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "87fc0ed59fec49b0bf8592a205bfb815": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8bb2dd04317442ebeeec528e85e4446": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "94342dcf55844b86aa49b0020dea0229": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "22c33156634e4a78930276ff7fabb752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "77f5685ad83f453fbc5256b97b559d25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "262450ad6ec54d3fb1d6a5db6234bdc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0b8c10abb31947f2b152642bfc9f9f3c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fd389c334c504506961c5f181ba1935e",
              "IPY_MODEL_f1c70b5aa886434380a0889601771962",
              "IPY_MODEL_4c0ef5f8037546dfbf034b95db5cf60f"
            ]
          }
        },
        "0b8c10abb31947f2b152642bfc9f9f3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fd389c334c504506961c5f181ba1935e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2fcc1cc90cbd4772bf97f0f087baa203",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_65ec3a228bf044139994866eb20e0125"
          }
        },
        "f1c70b5aa886434380a0889601771962": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1247815110eb4a549254ab2fab3b1469",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 648,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 648,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b9c992bdba1247fa8de73de4d4450a8f"
          }
        },
        "4c0ef5f8037546dfbf034b95db5cf60f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_46f108722684456f9234e07e6d66c306",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 648/648 [00:00&lt;00:00, 15.8kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4aa0163e080b457480884358c5fff5e1"
          }
        },
        "2fcc1cc90cbd4772bf97f0f087baa203": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "65ec3a228bf044139994866eb20e0125": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1247815110eb4a549254ab2fab3b1469": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b9c992bdba1247fa8de73de4d4450a8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "46f108722684456f9234e07e6d66c306": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4aa0163e080b457480884358c5fff5e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d07f7b8b839247d78e9ef5cbc7d2ee8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_605d5c4b0b2c485baffa466531e3e9c6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8ad189bbdc0c476491aced94220ffcd0",
              "IPY_MODEL_65af6b212c944a949f03486dbc387046",
              "IPY_MODEL_ee13552df4ac4c3cba143b1aced386f2"
            ]
          }
        },
        "605d5c4b0b2c485baffa466531e3e9c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ad189bbdc0c476491aced94220ffcd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b6f9988aa66346e189fa0056b8f1c499",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_38e0fc9dd9cc4b5ba9c33cfe1ec26e9b"
          }
        },
        "65af6b212c944a949f03486dbc387046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cbfb4d104bfd411b9311a6e192944845",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 241796,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 241796,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_185188460afa456ebdba76fbfa0d898a"
          }
        },
        "ee13552df4ac4c3cba143b1aced386f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c40e92568be34ec5abd41978db13ca78",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 236k/236k [00:00&lt;00:00, 947kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9e215a11879407391ea6353e0e56b2c"
          }
        },
        "b6f9988aa66346e189fa0056b8f1c499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "38e0fc9dd9cc4b5ba9c33cfe1ec26e9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cbfb4d104bfd411b9311a6e192944845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "185188460afa456ebdba76fbfa0d898a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c40e92568be34ec5abd41978db13ca78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9e215a11879407391ea6353e0e56b2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e3fb938767aa44fdb6e016575e55fa62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bacb63ca659c4aafb3191cb2505b2618",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f68873f2934e4cf8b9520a1b5df4f077",
              "IPY_MODEL_6882522226b84b408a00effbe6fee01f",
              "IPY_MODEL_3cd0ef7796194e11ab11e97f3aa4af2d"
            ]
          }
        },
        "bacb63ca659c4aafb3191cb2505b2618": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f68873f2934e4cf8b9520a1b5df4f077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_60f78567774a4d128a1f69edb664ba83",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3e5646f456af4c3596efd1045d70ba02"
          }
        },
        "6882522226b84b408a00effbe6fee01f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dc74697a116343c197af75702837b98c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 480199,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 480199,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e001b19da234cbd872daa1d8a9c84f0"
          }
        },
        "3cd0ef7796194e11ab11e97f3aa4af2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bc2a409826904e06ae48311dde1a728b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 469k/469k [00:00&lt;00:00, 1.11MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_de33cb891b324d3998045f84b220f167"
          }
        },
        "60f78567774a4d128a1f69edb664ba83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3e5646f456af4c3596efd1045d70ba02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc74697a116343c197af75702837b98c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e001b19da234cbd872daa1d8a9c84f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc2a409826904e06ae48311dde1a728b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "de33cb891b324d3998045f84b220f167": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e80a6e90941049ddaac42b9ff475cd7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cc2b10b67c2948e6904f286359146308",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_63bfaeba0c15405289fe9c0f552a4779",
              "IPY_MODEL_16279b1cc0b445748ddbd84d58d3909f",
              "IPY_MODEL_2a6e2b9123b44475a311eead3cd3edbe"
            ]
          }
        },
        "cc2b10b67c2948e6904f286359146308": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "63bfaeba0c15405289fe9c0f552a4779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6297610fd6684a19bcb63226fb6beb72",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b9e9a6ec7ab7451992ba8809fe57f241"
          }
        },
        "16279b1cc0b445748ddbd84d58d3909f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_056049e6df4841ae8cf050c190a369f1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 134,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 134,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8464aaf45c5c4a3c915bd3f9a5558a52"
          }
        },
        "2a6e2b9123b44475a311eead3cd3edbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a0ab09faaef34a0c9dd206d9df35da0b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 134/134 [00:00&lt;00:00, 3.33kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3c4f27697bd4dd09ab00b3ac711882f"
          }
        },
        "6297610fd6684a19bcb63226fb6beb72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b9e9a6ec7ab7451992ba8809fe57f241": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "056049e6df4841ae8cf050c190a369f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8464aaf45c5c4a3c915bd3f9a5558a52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a0ab09faaef34a0c9dd206d9df35da0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3c4f27697bd4dd09ab00b3ac711882f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# BETO Fine-Tuning For Sexism Detection\n",
        "\n",
        "Jackson Pullman, Aintzane Aboitiz, and Jeronimo Fueyo\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX_ZDhicpHkV"
      },
      "source": [
        "# 1. Setup and Acknowledgements\n",
        "This code was heavily adapted from 3 main sources:\n",
        "\n",
        "1.) Chris Mccormick: https://mccormickml.com/2019/07/22/BERT-fine-tuning/\n",
        "\n",
        "2.) Victoria Acuna: https://www.kaggle.com/victoriaacuna/beto-fine-tuning/notebook\n",
        "\n",
        "3.) GitHub Contributer vfdev-5: https://github.com/pytorch/captum/issues/150\n",
        "\n",
        "We owe them an immense debt of gratitude as the majority of the functions and workflow across this notebook are snipped together from their tutorials and help! "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSU7yERLP_66"
      },
      "source": [
        "## 1.1. Using Colab GPU for Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GI0iOY8zvZzL"
      },
      "source": [
        "\n",
        "Google Colab offers free GPUs and TPUs! Since we'll be training a large neural network it's best to take advantage of this (in this case we'll attach a GPU), otherwise training will take a very long time.\n",
        "\n",
        "A GPU can be added by going to the menu and selecting:\n",
        "\n",
        "`Edit 🡒 Notebook Settings 🡒 Hardware accelerator 🡒 (GPU)`\n",
        "\n",
        "Then run the following cell to confirm that the GPU is detected."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88dcfe3e-4a1c-4708-c87a-75a0f7415226"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqG7FzRVFEIv"
      },
      "source": [
        "In order for torch to use the GPU, we need to identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7026c7ce-7b26-440f-9c18-77ef754bedb9"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla K80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ElsnSNUridI"
      },
      "source": [
        "## 1.2. Installing the Hugging Face Library\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3d56fc0-9784-4ba4-f80f-ba5886a5843a"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.15.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 33.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 45.7 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 40.8 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 507 kB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.2.1 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "# 2. Loading EXIST Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JrUHXms16cn"
      },
      "source": [
        "## 2.1. Download & Extract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08pO03Ff1BjI"
      },
      "source": [
        "The dataset can be obtained on our github"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQUy9Tat2EF_"
      },
      "source": [
        "## 2.2. Parse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset into a pandas dataframe.\n",
        "df_2 = pd.read_csv(\"./EXIST2021_test_labeled.tsv\",delimiter='\\t')\n",
        "df_2 = df_2[df_2.language == \"es\"]\n",
        "# Report the number of sentences.\n",
        "#df_2 = df_2[df_2.source == \"twitter\"]\n",
        "print('Number of test sentences: {:,}\\n'.format(df_2.shape[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-w7mgJ67ABsp",
        "outputId": "df7a9f97-464f-4d88-9807-d19c0f2b6dfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test sentences: 2,160\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UkeC7SG2krJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "3d71716d-cef9-489d-8be9-1f5544bce5ce"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./EXIST2021_training.tsv\",delimiter='\\t')\n",
        "df = df[df.language == \"es\"]\n",
        "# Report the number of sentences.\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Display 10 random rows from the data.\n",
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training sentences: 3,541\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a7d71130-3c20-404f-8a47-e3fe37650cb0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_case</th>\n",
              "      <th>id</th>\n",
              "      <th>source</th>\n",
              "      <th>language</th>\n",
              "      <th>text</th>\n",
              "      <th>task1</th>\n",
              "      <th>task2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4710</th>\n",
              "      <td>EXIST2021</td>\n",
              "      <td>4711</td>\n",
              "      <td>twitter</td>\n",
              "      <td>es</td>\n",
              "      <td>@saeransunshine Gracias niñata</td>\n",
              "      <td>sexist</td>\n",
              "      <td>stereotyping-dominance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4081</th>\n",
              "      <td>EXIST2021</td>\n",
              "      <td>4082</td>\n",
              "      <td>twitter</td>\n",
              "      <td>es</td>\n",
              "      <td>@LuisLab63 @enzothebestok Todos (los chorros y...</td>\n",
              "      <td>non-sexist</td>\n",
              "      <td>non-sexist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5754</th>\n",
              "      <td>EXIST2021</td>\n",
              "      <td>5755</td>\n",
              "      <td>twitter</td>\n",
              "      <td>es</td>\n",
              "      <td>@okdiario Esta muy claro. No sé por qué alguie...</td>\n",
              "      <td>sexist</td>\n",
              "      <td>ideological-inequality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5731</th>\n",
              "      <td>EXIST2021</td>\n",
              "      <td>5732</td>\n",
              "      <td>twitter</td>\n",
              "      <td>es</td>\n",
              "      <td>¿Con esas preguntas tan maricas se consiguen 1...</td>\n",
              "      <td>sexist</td>\n",
              "      <td>misogyny-non-sexual-violence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5829</th>\n",
              "      <td>EXIST2021</td>\n",
              "      <td>5830</td>\n",
              "      <td>twitter</td>\n",
              "      <td>es</td>\n",
              "      <td>pensamiento intrusivo de ser una mujer florero...</td>\n",
              "      <td>sexist</td>\n",
              "      <td>stereotyping-dominance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6596</th>\n",
              "      <td>EXIST2021</td>\n",
              "      <td>6597</td>\n",
              "      <td>twitter</td>\n",
              "      <td>es</td>\n",
              "      <td>quería decir esto porque ,yo la primera, la ge...</td>\n",
              "      <td>non-sexist</td>\n",
              "      <td>non-sexist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3617</th>\n",
              "      <td>EXIST2021</td>\n",
              "      <td>3618</td>\n",
              "      <td>twitter</td>\n",
              "      <td>es</td>\n",
              "      <td>A mí me interesa más la declaración fiscal de ...</td>\n",
              "      <td>non-sexist</td>\n",
              "      <td>non-sexist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6807</th>\n",
              "      <td>EXIST2021</td>\n",
              "      <td>6808</td>\n",
              "      <td>twitter</td>\n",
              "      <td>es</td>\n",
              "      <td>@OcineTweets @Xmadrid6 @Pau4Mostoles @taxialco...</td>\n",
              "      <td>sexist</td>\n",
              "      <td>stereotyping-dominance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5413</th>\n",
              "      <td>EXIST2021</td>\n",
              "      <td>5414</td>\n",
              "      <td>twitter</td>\n",
              "      <td>es</td>\n",
              "      <td>@MedraPRO3D Porque la casa era el único lugar ...</td>\n",
              "      <td>sexist</td>\n",
              "      <td>stereotyping-dominance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3523</th>\n",
              "      <td>EXIST2021</td>\n",
              "      <td>3524</td>\n",
              "      <td>twitter</td>\n",
              "      <td>es</td>\n",
              "      <td>Feministas Morelianas Exigen Al Congreso Legal...</td>\n",
              "      <td>non-sexist</td>\n",
              "      <td>non-sexist</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7d71130-3c20-404f-8a47-e3fe37650cb0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a7d71130-3c20-404f-8a47-e3fe37650cb0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a7d71130-3c20-404f-8a47-e3fe37650cb0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      test_case    id  ...       task1                         task2\n",
              "4710  EXIST2021  4711  ...      sexist        stereotyping-dominance\n",
              "4081  EXIST2021  4082  ...  non-sexist                    non-sexist\n",
              "5754  EXIST2021  5755  ...      sexist        ideological-inequality\n",
              "5731  EXIST2021  5732  ...      sexist  misogyny-non-sexual-violence\n",
              "5829  EXIST2021  5830  ...      sexist        stereotyping-dominance\n",
              "6596  EXIST2021  6597  ...  non-sexist                    non-sexist\n",
              "3617  EXIST2021  3618  ...  non-sexist                    non-sexist\n",
              "6807  EXIST2021  6808  ...      sexist        stereotyping-dominance\n",
              "5413  EXIST2021  5414  ...      sexist        stereotyping-dominance\n",
              "3523  EXIST2021  3524  ...  non-sexist                    non-sexist\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blqIvQaQncdJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "eee548a9-0413-4730-d150-881f3409f004"
      },
      "source": [
        "df.loc[df.task1 == 'sexist'].sample(5)[['text', 'task1']]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e09ec198-9437-4eef-9451-9304faefc5d9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>task1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6644</th>\n",
              "      <td>@MisterDeivid_ no sabía que tenían computadore...</td>\n",
              "      <td>sexist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5561</th>\n",
              "      <td>@LaPanteraPoeta Para mi esposa que fue la que ...</td>\n",
              "      <td>sexist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3538</th>\n",
              "      <td>@pedroferriz3 Nooo las mujeres que te gustan s...</td>\n",
              "      <td>sexist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6138</th>\n",
              "      <td>Cuerpo perfecto.Imperfecta pero divina.Diosa d...</td>\n",
              "      <td>sexist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5327</th>\n",
              "      <td>@VaniiaBlludau saliendo a decir que “se deja p...</td>\n",
              "      <td>sexist</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e09ec198-9437-4eef-9451-9304faefc5d9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e09ec198-9437-4eef-9451-9304faefc5d9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e09ec198-9437-4eef-9451-9304faefc5d9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   text   task1\n",
              "6644  @MisterDeivid_ no sabía que tenían computadore...  sexist\n",
              "5561  @LaPanteraPoeta Para mi esposa que fue la que ...  sexist\n",
              "3538  @pedroferriz3 Nooo las mujeres que te gustan s...  sexist\n",
              "6138  Cuerpo perfecto.Imperfecta pero divina.Diosa d...  sexist\n",
              "5327  @VaniiaBlludau saliendo a decir que “se deja p...  sexist"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Visualize training data distribution...\n",
        "sns.barplot(x=['1', '0'], y=df['task1'].value_counts(), palette=\"rocket\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Y7W1dl1uJXvn",
        "outputId": "1ab228f5-d5d8-4422-a954-479d93a5b317"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuE5BqICAne2"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.text.values\n",
        "labels = df.task1.values\n",
        "#Convert Labels to binary numeric format\n",
        "for x in np.arange(len(labels)):\n",
        "  if labels[x] == \"sexist\":\n",
        "    labels[x] = 1\n",
        "  elif labels[x] == \"non-sexist\":\n",
        "    labels[x] = 0\n",
        "labels = labels.astype(\"int64\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "# 3. Tokenization & Input Formatting\n",
        "\n",
        "In this section, we'll transform our dataset into the format that BETO can be trained on."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8kEDRvShcU5"
      },
      "source": [
        "## 3.1. BETO Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194,
          "referenced_widgets": [
            "2cfb32ada124465193c107f629e46715",
            "fe6cde81f8104a01995eba21b1c66f98",
            "c989bd8fb3564c9ab0c656e964806584",
            "0eef865155084f9f9cf271e44765fb9a",
            "905384f44e9e41d78eedb759c84bf06c",
            "e86dfba8d051433c96fb45bb40d6b4dd",
            "87fc0ed59fec49b0bf8592a205bfb815",
            "b8bb2dd04317442ebeeec528e85e4446",
            "94342dcf55844b86aa49b0020dea0229",
            "22c33156634e4a78930276ff7fabb752",
            "77f5685ad83f453fbc5256b97b559d25",
            "262450ad6ec54d3fb1d6a5db6234bdc2",
            "0b8c10abb31947f2b152642bfc9f9f3c",
            "fd389c334c504506961c5f181ba1935e",
            "f1c70b5aa886434380a0889601771962",
            "4c0ef5f8037546dfbf034b95db5cf60f",
            "2fcc1cc90cbd4772bf97f0f087baa203",
            "65ec3a228bf044139994866eb20e0125",
            "1247815110eb4a549254ab2fab3b1469",
            "b9c992bdba1247fa8de73de4d4450a8f",
            "46f108722684456f9234e07e6d66c306",
            "4aa0163e080b457480884358c5fff5e1",
            "d07f7b8b839247d78e9ef5cbc7d2ee8e",
            "605d5c4b0b2c485baffa466531e3e9c6",
            "8ad189bbdc0c476491aced94220ffcd0",
            "65af6b212c944a949f03486dbc387046",
            "ee13552df4ac4c3cba143b1aced386f2",
            "b6f9988aa66346e189fa0056b8f1c499",
            "38e0fc9dd9cc4b5ba9c33cfe1ec26e9b",
            "cbfb4d104bfd411b9311a6e192944845",
            "185188460afa456ebdba76fbfa0d898a",
            "c40e92568be34ec5abd41978db13ca78",
            "c9e215a11879407391ea6353e0e56b2c",
            "e3fb938767aa44fdb6e016575e55fa62",
            "bacb63ca659c4aafb3191cb2505b2618",
            "f68873f2934e4cf8b9520a1b5df4f077",
            "6882522226b84b408a00effbe6fee01f",
            "3cd0ef7796194e11ab11e97f3aa4af2d",
            "60f78567774a4d128a1f69edb664ba83",
            "3e5646f456af4c3596efd1045d70ba02",
            "dc74697a116343c197af75702837b98c",
            "8e001b19da234cbd872daa1d8a9c84f0",
            "bc2a409826904e06ae48311dde1a728b",
            "de33cb891b324d3998045f84b220f167",
            "e80a6e90941049ddaac42b9ff475cd7a",
            "cc2b10b67c2948e6904f286359146308",
            "63bfaeba0c15405289fe9c0f552a4779",
            "16279b1cc0b445748ddbd84d58d3909f",
            "2a6e2b9123b44475a311eead3cd3edbe",
            "6297610fd6684a19bcb63226fb6beb72",
            "b9e9a6ec7ab7451992ba8809fe57f241",
            "056049e6df4841ae8cf050c190a369f1",
            "8464aaf45c5c4a3c915bd3f9a5558a52",
            "a0ab09faaef34a0c9dd206d9df35da0b",
            "b3c4f27697bd4dd09ab00b3ac711882f"
          ]
        },
        "outputId": "00260ba7-17eb-4843-ceb1-55394988e32b"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load the BETO tokenizer.\n",
        "print('Loading BETO tokenizer...')\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-cased\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2cfb32ada124465193c107f629e46715",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/364 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "262450ad6ec54d3fb1d6a5db6234bdc2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/648 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d07f7b8b839247d78e9ef5cbc7d2ee8e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/236k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3fb938767aa44fdb6e016575e55fa62",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/469k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e80a6e90941049ddaac42b9ff475cd7a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/134 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFzmtleW6KmJ"
      },
      "source": [
        "Let's apply the tokenizer to one sentence just to see the output.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLIbudgfh6F0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cdaf638-a8a5-425f-b7d2-b1a0428f347a"
      },
      "source": [
        "# Print the original sentence.\n",
        "print(' Original: ', sentences[0])\n",
        "\n",
        "# Print the sentence split into tokens.\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "\n",
        "# Print the sentence mapped to token ids.\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  Nadie te va a tratar tan bien como un hombre que te lo quiere meter por primera vez.\n",
            "Tokenized:  ['Nadie', 'te', 'va', 'a', 'tratar', 'tan', 'bien', 'como', 'un', 'hombre', 'que', 'te', 'lo', 'quiere', 'meter', 'por', 'primera', 'vez', '.']\n",
            "Token IDs:  [4228, 1240, 1768, 1013, 4884, 1431, 1311, 1184, 1049, 1900, 1038, 1240, 1114, 2453, 7359, 1096, 2076, 1480, 1009]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeNIc4auFUdF"
      },
      "source": [
        "When we actually convert all of our sentences, we'll use the `tokenize.encode` function to handle both steps, rather than calling `tokenize` and `convert_tokens_to_ids` separately. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viKGCCh8izww"
      },
      "source": [
        "## 3.2. Required Formatting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDcqNlvVhL5W"
      },
      "source": [
        "The above code left out a few required formatting steps that we'll look at here.\n",
        "\n",
        "\n",
        "We are required to:\n",
        "1. Add special tokens to the start and end of each sentence.\n",
        "2. Pad & truncate all sentences to a single constant length.\n",
        "3. Explicitly differentiate real tokens from padding tokens with the \"attention mask\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6mceWWOjZnw"
      },
      "source": [
        "### Special Tokens\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ykk0P9JiKtVe"
      },
      "source": [
        "\n",
        "**`[SEP]`**\n",
        "\n",
        "At the end of every sentence, we need to append the special `[SEP]` token. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86C9objaKu8f"
      },
      "source": [
        "**`[CLS]`**\n",
        "\n",
        "For classification tasks, we must prepend the special `[CLS]` token to the beginning of every sentence.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u51v0kFxeteu"
      },
      "source": [
        "### Sentence Length & Attention Mask\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPNuwqZVK3T6"
      },
      "source": [
        "\n",
        "BETO has two constraints:\n",
        "1. All sentences must be padded or truncated to a single, fixed length.\n",
        "2. The maximum sentence length is 512 tokens.\n",
        "\n",
        "Padding is done with a special `[PAD]` token, which is at index 0 in the BETO vocabulary. \n",
        "\n",
        "The \"Attention Mask\" is simply an array of 1s and 0s indicating which tokens are padding and which aren't.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6w8elb-58GJ"
      },
      "source": [
        "## 3.3. Tokenize Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Studying sentences length distribution\n",
        "seq_len = [len(tweet.split()) for tweet in sentences]\n",
        "\n",
        "pd.Series(seq_len).hist(bins=30)"
      ],
      "metadata": {
        "id": "i3Fz5kGWqFoS",
        "outputId": "b9ed3eee-15eb-45f8-fc51-c68ca42d1924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7feb821b9650>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M296yz577fV"
      },
      "source": [
        "Just in case there are some longer test sentences, I'll set the maximum length to 100.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIWAoWL2RK1p"
      },
      "source": [
        "Now we're ready to perform the real tokenization.\n",
        "\n",
        "The `tokenizer.encode_plus` function combines multiple steps for us:\n",
        "\n",
        "1. Split the sentence into tokens.\n",
        "2. Add the special `[CLS]` and `[SEP]` tokens.\n",
        "3. Map the tokens to their IDs.\n",
        "4. Pad or truncate all sentences to the same length.\n",
        "5. Create the attention masks which explicitly differentiate real tokens from `[PAD]` tokens.\n",
        "\n",
        "The first four features are in `tokenizer.encode`, but I'm using `tokenizer.encode_plus` to get the fifth item (attention masks). Documentation is [here](https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0ae9034-8ad5-4594-d844-7923012e22a2"
      },
      "source": [
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 100,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  Nadie te va a tratar tan bien como un hombre que te lo quiere meter por primera vez.\n",
            "Token IDs: tensor([   4, 4228, 1240, 1768, 1013, 4884, 1431, 1311, 1184, 1049, 1900, 1038,\n",
            "        1240, 1114, 2453, 7359, 1096, 2076, 1480, 1009,    5,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
            "           1,    1,    1,    1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRp4O7D295d_"
      },
      "source": [
        "## 3.4. Training & Validation Split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu0ao7p8rb06"
      },
      "source": [
        "Divide up our training set to use 90% for training and 10% for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a4e9a57-ae7f-449d-b2cc-89968d9c8c59"
      },
      "source": [
        "from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.9 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3,186 training samples\n",
            "  355 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD9i6Z2pG-sN"
      },
      "source": [
        "We'll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 32\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bwa6Rts-02-"
      },
      "source": [
        "# 4. Train Our Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xYQ3iLO08SX"
      },
      "source": [
        "Now that our input data is properly formatted, it's time to fine tune the BERT model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc"
      },
      "source": [
        "## 4.1. AutoModelForSequenceClassification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXYitPoE-cjH"
      },
      "source": [
        "\n",
        "\n",
        "We'll be using [BertForSequenceClassification](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2ce22b2-cf35-425b-e142-2773eb9d0cd4"
      },
      "source": [
        "from transformers import AutoModelForSequenceClassification, AdamW, AutoConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"dccuchile/bert-base-spanish-wwm-cased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['bert.pooler.dense.bias', 'classifier.weight', 'classifier.bias', 'bert.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(31002, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0Jv6c7-HHDW"
      },
      "source": [
        "Just for curiosity's sake, we can browse all of the model's parameters by name here.\n",
        "\n",
        "In the below cell, I've printed out the names and dimensions of the weights for:\n",
        "\n",
        "1. The embedding layer.\n",
        "2. The first of the twelve transformers.\n",
        "3. The output layer.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PIiVlDYCtSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2eac92f-91e6-49cc-ff33-c4530a7c9240"
      },
      "source": [
        "# Exploring number of parameters in model.\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print('The model we defined has a total of ', trainable_params, ' trainable parameters.')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model we defined has a total of  109852418  trainable parameters.\n",
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (31002, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRWT-D4U_Pvx"
      },
      "source": [
        "## 4.2. Optimizer & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o-VEBobKwHk"
      },
      "source": [
        "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
        "\n",
        "For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)):\n",
        "\n",
        ">- **Batch size:** 16, 32  \n",
        "- **Learning rate (Adam):** 5e-5, 3e-5, 2e-5  \n",
        "- **Number of epochs:** 2, 3, 4 \n",
        "\n",
        "We chose:\n",
        "* Batch size: 32 (set when creating our DataLoaders)\n",
        "* Learning rate: 2e-5\n",
        "* Epochs: 4 (we'll see that this is probably too many...)\n",
        "\n",
        "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
        "\n",
        "You can find the creation of the AdamW optimizer in `run_glue.py` [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO"
      },
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "epochs = 2\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqfmWwUR_Sox"
      },
      "source": [
        "## 4.3. Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QXZhFb4LnV5"
      },
      "source": [
        "Below is our training loop. \n",
        "\n",
        "**Training:**\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Clear out the gradients calculated in the previous pass. \n",
        "    - In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
        "- Forward pass (feed input data through the network)\n",
        "- Backward pass (backpropagation)\n",
        "- Tell the network to update parameters with optimizer.step()\n",
        "- Track variables for monitoring progress\n",
        "\n",
        "**Evalution:**\n",
        "- Unpack our data inputs and labels\n",
        "- Load data onto the GPU for acceleration\n",
        "- Forward pass (feed input data through the network)\n",
        "- Compute loss on our validation data and track variables for monitoring progress\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE5B99H5H2-W"
      },
      "source": [
        "Define a helper function for calculating accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNhRtWPXH9C3"
      },
      "source": [
        "Helper function for formatting elapsed times as `hh:mm:ss`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5baaf23f-ee7b-4087-adaa-0edf58238c3f"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "        # function and pass down the arguments. The `forward` function is \n",
        "        # documented here: \n",
        "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "        # The results are returned in a results object, documented here:\n",
        "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "        # Specifically, we'll get the loss (because we provided labels) and the\n",
        "        # \"logits\"--the model outputs prior to activation.\n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            result = model(b_input_ids, \n",
        "                           token_type_ids=None, \n",
        "                           attention_mask=b_input_mask,\n",
        "                           labels=b_labels,\n",
        "                           return_dict=True)\n",
        "\n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like the \n",
        "        # softmax.\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of    100.    Elapsed: 0:00:51.\n",
            "  Batch    80  of    100.    Elapsed: 0:01:42.\n",
            "\n",
            "  Average training loss: 0.63\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.51\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 2 / 2 ========\n",
            "Training...\n",
            "  Batch    40  of    100.    Elapsed: 0:00:51.\n",
            "  Batch    80  of    100.    Elapsed: 0:01:41.\n",
            "\n",
            "  Average training loss: 0.43\n",
            "  Training epcoh took: 0:02:06\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.79\n",
            "  Validation Loss: 0.49\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:04:23 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4"
      },
      "source": [
        "Let's view the summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "c348bfe5-7e6d-483d-d851-b7a900be206e"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Display floats with two decimal places.\n",
        "pd.set_option('precision', 2)\n",
        "\n",
        "# Create a DataFrame from our training statistics.\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "# Use the 'epoch' as the row index.\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "# A hack to force the column headers to wrap.\n",
        "#df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "# Display the table.\n",
        "df_stats"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-493825b1-3323-4e2a-9842-4326222fbde2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.63</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0:02:06</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.43</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0:02:06</td>\n",
              "      <td>0:00:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-493825b1-3323-4e2a-9842-4326222fbde2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-493825b1-3323-4e2a-9842-4326222fbde2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-493825b1-3323-4e2a-9842-4326222fbde2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.63         0.51           0.78       0:02:06         0:00:05\n",
              "2               0.43         0.49           0.79       0:02:06         0:00:05"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "c135b8ee-5a93-433d-aac9-4a9f17e1a409"
      },
      "source": [
        "#Plotting Training and Validation Loss\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "# 5. Performance On Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg42jJqqM68F"
      },
      "source": [
        "### 5.1. Data Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWe0_JW21MyV"
      },
      "source": [
        "\n",
        "We'll need to apply all of the same steps that we did for the training data to prepare our test data set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05f59728-7db8-453e-bd87-7882ff58bdd7"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset into a pandas dataframe.\n",
        "df = pd.read_csv(\"./EXIST2021_test_labeled.tsv\",delimiter='\\t')\n",
        "df = df[df.language == \"es\"]\n",
        "# Report the number of sentences.\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "\n",
        "# Create sentence and label lists\n",
        "sentences = df.text.values\n",
        "labels = df.task1.values\n",
        "#Change values to numeric\n",
        "for x in np.arange(len(labels)):\n",
        "  if labels[x] == \"sexist\":\n",
        "    labels[x] = 1\n",
        "  elif labels[x] == \"non-sexist\":\n",
        "    labels[x] = 0\n",
        "labels = labels.astype(\"int64\")\n",
        "\n",
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Set the batch size.  \n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of test sentences: 2,160\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2232: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16lctEOyNFik"
      },
      "source": [
        "## 5.2. Evaluate on Test Set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhR99IISNMg9"
      },
      "source": [
        "\n",
        "With the test set prepared, we can apply our fine-tuned model to generate predictions on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89b9082c-416a-4390-f1b6-3cae16dc506c"
      },
      "source": [
        "# Prediction on test set\n",
        "\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "  \n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('    DONE.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting labels for 2,160 test sentences...\n",
            "    DONE.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculate the full list of predictions\n",
        "pred = []\n",
        "for i in range(len(true_labels)):\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  pred.append(pred_labels_i)"
      ],
      "metadata": {
        "id": "FiDS66p6xbuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Flatten the predictioned labels and true labels\n",
        "true = np.concatenate(true_labels).ravel().tolist()\n",
        "pred = np.concatenate(pred).ravel().tolist()"
      ],
      "metadata": {
        "id": "2PB1-WXH23cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Examine a variety of evaluation metrics\n",
        "from sklearn.metrics import  accuracy_score, f1_score, precision_score, recall_score\n",
        "print(\"Accuracy Score: \", np.round(accuracy_score(true, pred),4))\n",
        "print(\"Precision Score: \", np.round(precision_score(true, pred),4))\n",
        "print(\"Recall Score: \", np.round(recall_score(true, pred),4))\n",
        "print(\"F1 Score: \",np.round(f1_score(true, pred),4))"
      ],
      "metadata": {
        "id": "b18aNoTFy45Q",
        "outputId": "f15e6fc9-0db9-422b-aadc-92cc20172e5b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score:  0.7745\n",
            "Precision Score:  0.8093\n",
            "Recall Score:  0.7409\n",
            "F1 Score:  0.7736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Evaluating Model Performance with Captum"
      ],
      "metadata": {
        "id": "QyUCOV4-m0bP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"Captum (“comprehension” in Latin) is an open source, extensible library for model interpretability built on PyTorch\".\n",
        "The integrated gradients tool will tell how specific words are contributing towards the classification of the output. Words will be color coded by the degree which they influence the sentence being labeled \"sexist\" (1) or \"non-sexist\" (0)."
      ],
      "metadata": {
        "id": "wUjmwxpso4aX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Install Captum \n",
        "!pip install captum"
      ],
      "metadata": {
        "id": "mEUrvZGknAVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import dependencies\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from captum.attr import IntegratedGradients\n",
        "from captum.attr import InterpretableEmbeddingBase, TokenReferenceBase\n",
        "from captum.attr import visualization\n",
        "from captum.attr import configure_interpretable_embedding_layer, remove_interpretable_embedding_layer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3Xy0NpYbd-A",
        "outputId": "a81057b2-ab4b-43e2-93dc-d6ce03076fca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: captum in /usr/local/lib/python3.7/dist-packages (0.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from captum) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.7/dist-packages (from captum) (1.10.0+cu111)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from captum) (3.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.2->captum) (3.10.0.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->captum) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->captum) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to split forward pass into two part: \n",
        "# 1) embeddings computation\n",
        "# 2) classification\n",
        "\n",
        "def compute_bert_outputs(model_bert, embedding_output, attention_mask=None, head_mask=None):\n",
        "    if attention_mask is None:\n",
        "        attention_mask = torch.ones(embedding_output.shape[0], embedding_output.shape[1]).to(embedding_output)\n",
        "\n",
        "    extended_attention_mask = attention_mask.unsqueeze(1).unsqueeze(2)\n",
        "\n",
        "    extended_attention_mask = extended_attention_mask.to(dtype=next(model_bert.parameters()).dtype) # fp16 compatibility\n",
        "    extended_attention_mask = (1.0 - extended_attention_mask) * -10000.0\n",
        "\n",
        "    if head_mask is not None:\n",
        "        if head_mask.dim() == 1:\n",
        "            head_mask = head_mask.unsqueeze(0).unsqueeze(0).unsqueeze(-1).unsqueeze(-1)\n",
        "            head_mask = head_mask.expand(model_bert.config.num_hidden_layers, -1, -1, -1, -1)\n",
        "        elif head_mask.dim() == 2:\n",
        "            head_mask = head_mask.unsqueeze(1).unsqueeze(-1).unsqueeze(-1)  # We can specify head_mask for each layer\n",
        "        head_mask = head_mask.to(dtype=next(model_bert.parameters()).dtype) # switch to fload if need + fp16 compatibility\n",
        "    else:\n",
        "        head_mask = [None] * model_bert.config.num_hidden_layers\n",
        "\n",
        "    encoder_outputs = model_bert.encoder(embedding_output,\n",
        "                                         extended_attention_mask,\n",
        "                                         head_mask=head_mask)\n",
        "    sequence_output = encoder_outputs[0]\n",
        "    pooled_output = model_bert.pooler(sequence_output)\n",
        "    outputs = (sequence_output, pooled_output,) + encoder_outputs[1:]  # add hidden_states and attentions if they are here\n",
        "    return outputs  # sequence_output, pooled_output, (hidden_states), (attentions)    \n"
      ],
      "metadata": {
        "id": "mNjWRxjuchpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create wrapper class for our model which Captum can interact with.\n",
        "class BertModelWrapper(nn.Module):\n",
        "    \n",
        "    def __init__(self, model):\n",
        "        super(BertModelWrapper, self).__init__()\n",
        "        self.model = model\n",
        "        \n",
        "    def forward(self, embeddings):        \n",
        "        outputs = compute_bert_outputs(self.model.bert, embeddings)\n",
        "        pooled_output = outputs[1]\n",
        "        pooled_output = self.model.dropout(pooled_output)\n",
        "        logits = self.model.classifier(pooled_output)\n",
        "        return torch.softmax(logits, dim=1)[:, 1].unsqueeze(1)"
      ],
      "metadata": {
        "id": "NYcOotHMcizI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model_wrapper = BertModelWrapper(model)\n",
        "bert_model_wrapper = bert_model_wrapper.to(device)\n",
        "ig = IntegratedGradients(bert_model_wrapper)\n",
        "\n",
        "\n",
        "# accumalate couple samples in this array for visualization purposes\n",
        "vis_data_records_ig = []"
      ],
      "metadata": {
        "id": "YdOmcE5OcnUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function which will apply integrated gradients to the sentence.\n",
        "def interpret_sentence(model_wrapper, sentence, label=1):\n",
        "\n",
        "    model_wrapper.eval()\n",
        "    model_wrapper.zero_grad()\n",
        "    \n",
        "    input_ids = torch.tensor([tokenizer.encode(sentence, add_special_tokens=True)])\n",
        "    input_ids = input_ids.to(device)\n",
        "    input_embedding = model_wrapper.model.bert.embeddings(input_ids)\n",
        "    \n",
        "    # predict\n",
        "    pred = model_wrapper(input_embedding).item()\n",
        "    pred_ind = round(pred)\n",
        "\n",
        "    # compute attributions and approximation delta using integrated gradients\n",
        "    attributions_ig, delta = ig.attribute(input_embedding, n_steps=500, return_convergence_delta=True)\n",
        "\n",
        "    print('pred: ', pred_ind, '(', '%.2f' % pred, ')', ', delta: ', abs(delta))\n",
        "\n",
        "\n",
        "    tokens = tokenizer.convert_ids_to_tokens(input_ids[0].to('cpu').numpy().tolist())    \n",
        "    add_attributions_to_visualizer(attributions_ig, tokens, pred, pred_ind, label, delta, vis_data_records_ig)"
      ],
      "metadata": {
        "id": "QsIuEubCcqEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to help add word attributes for visualization\n",
        "def add_attributions_to_visualizer(attributions, tokens, pred, pred_ind, label, delta, vis_data_records):\n",
        "    attributions = attributions.sum(dim=2).squeeze(0)\n",
        "    attributions = attributions / torch.norm(attributions)\n",
        "    attributions = attributions.detach().cpu().numpy()\n",
        "    \n",
        "    # storing couple samples in an array for visualization purposes\n",
        "    vis_data_records.append(visualization.VisualizationDataRecord(\n",
        "                            attributions,\n",
        "                            pred,\n",
        "                            pred_ind,\n",
        "                            label,\n",
        "                            \"label\",\n",
        "                            attributions.sum(),       \n",
        "                            tokens[:len(attributions)],\n",
        "                            delta))    "
      ],
      "metadata": {
        "id": "KQdKlv49ctOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accumalate couple samples in this array for visualization purposes\n",
        "vis_data_records_ig = []"
      ],
      "metadata": {
        "id": "-lWxdVwelvWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Function call that will predict and assign attributes to a given sentence\n",
        "#Write in sentence yoou wish to analyze here.\n",
        "interpret_sentence(bert_model_wrapper, sentence=\"Cuantos anos tienes tipo? 3 o 4? Vate hijo de puta! a tu proprio hueco de mierda!\", label=0)\n",
        "visualization.visualize_text(vis_data_records_ig)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "_usyvGxacxhM",
        "outputId": "39fae61c-a77f-4d16-b0ec-ea0ee9a48401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-114-b22d6887f7cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0minterpret_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_model_wrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Cuantos anos tienes tipo? 3 o 4? Vate hijo de puta! a tu proprio hueco de mierda!\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvisualization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvisualize_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvis_data_records_ig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-63-76e9e3b93930>\u001b[0m in \u001b[0;36minterpret_sentence\u001b[0;34m(model_wrapper, sentence, label)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# compute attributions and approximation delta using integrated gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mattributions_ig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattribute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_embedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_convergence_delta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pred: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'('\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m')'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m', delta: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/captum/log/__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/captum/attr/_core/integrated_gradients.py\u001b[0m in \u001b[0;36mattribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta)\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madditional_forward_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m                 \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m             )\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/captum/attr/_core/integrated_gradients.py\u001b[0m in \u001b[0;36m_attribute\u001b[0;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, step_sizes_and_alphas)\u001b[0m\n\u001b[1;32m    352\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaled_features_tpl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mtarget_ind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_additional_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         )\n\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/captum/_utils/gradient.py\u001b[0m in \u001b[0;36mcompute_gradients\u001b[0;34m(forward_fn, inputs, target_ind, additional_forward_args)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# runs forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madditional_forward_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         assert outputs[0].numel() == 1, (\n\u001b[1;32m    113\u001b[0m             \u001b[0;34m\"Target not provided when necessary, cannot\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/captum/_utils/common.py\u001b[0m in \u001b[0;36m_run_forward\u001b[0;34m(forward_func, inputs, target, additional_forward_args)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0madditional_forward_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madditional_forward_args\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0;32melse\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m     )\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_select_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-f003d447b5fe>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, embeddings)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_bert_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-60-96393ee16b58>\u001b[0m in \u001b[0;36mcompute_bert_outputs\u001b[0;34m(model_bert, embedding_output, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m     24\u001b[0m     encoder_outputs = model_bert.encoder(embedding_output,\n\u001b[1;32m     25\u001b[0m                                          \u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                                          head_mask=head_mask)\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_bert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m                 )\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself_attn_past_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         )\n\u001b[1;32m    479\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_probs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[0mnew_context_layer_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_head_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mcontext_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_context_layer_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 40.00 MiB (GPU 0; 11.17 GiB total capacity; 10.02 GiB already allocated; 15.81 MiB free; 10.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    }
  ]
}
